{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import openai library\n",
    "import openai\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function (chatbot) that takes in a prompt and various chatbot args as input and returns response \n",
    "def chatbot(model, prompt, max_tokens, temperature, n ,top_p, frequency_penalty, presence_penalty):\n",
    "    response = client.chat.completions.create(model = model,\n",
    "                                            messages = [{\"role\":\"user\",\"content\":f'{prompt}'}],\n",
    "                                            max_tokens = max_tokens,  \n",
    "                                            temperature = temperature,\n",
    "                                            n = n,\n",
    "                                            top_p = top_p,\n",
    "                                            frequency_penalty = frequency_penalty,\n",
    "                                            presence_penalty = presence_penalty,\n",
    "                                            #stop = stop\n",
    "        \n",
    "    )\n",
    "    return response#.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt = \"Provide me a recipe for a cheesecake\"\n",
    "\n",
    "# Arguments for the chatbot parameters\n",
    "model = \"gpt-4o-mini\"\n",
    "max_tokens = 100         # this changes the number of tokens on the response from the the API\n",
    "temperature = 2          # controls the randomness of the response (0: very conservative and 2: very bold)\n",
    "n=2                      # number of responses\n",
    "top_p = 1                # also controls randomness of response (0.1: very conservative, limits the model to choose the top 10% of probabe words and 1: more creative, allows the model to consider a wider array of word choices)\n",
    "frequency_penalty = 1    # between -2 and 2. Positive valuers penalize frequent words. Negative words encourage repetition of words\n",
    "presence_penalty= 1      # between -2 and 2. \n",
    "stop = [\"\\n\"]            # specifies where the model should end its response. In this case, when it reaches a newline, the model stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-ANgF9b3xr0Lrb8ROdnusXRPkkPuam',\n",
       " 'choices': [{'finish_reason': 'length',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Sure! Here’s a classic cheesecake recipe that is creamy and delicious. This recipe will make a 9-inch cheesecake.\\n\\n### Classic Cheesecake Recipe\\n\\n#### Ingredients:\\n\\n**For the crust:**\\n- 1 ½ cups graham cracker crumbs\\n- ¼ cup granulated sugar\\n- ½ cup unsalted butter, melted\\n\\n**For the filling:**\\n- 4 (8 oz) packages cream cheese, softened\\n- 1 cup granulated sugar\\n- 1 teaspoon vanilla',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant'}},\n",
       "  {'finish_reason': 'length',\n",
       "   'index': 1,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Sure! Here’s a classic cheesecake recipe that is creamy and delicious. This recipe will make a 9-inch cheesecake.\\n\\n### Classic Cheesecake Recipe\\n\\n#### Ingredients:\\n\\n**For the crust:**\\n- 1 ½ cups graham cracker crumbs\\n- ¼ cup granulated sugar\\n- ½ cup unsalted butter, melted\\n\\n**For the filling:**\\n- 4 (8 oz) packages cream cheese, softened\\n- 1 cup granulated sugar\\n- 1 teaspoon vanilla',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1730207291,\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_f59a81427f',\n",
       " 'usage': {'completion_tokens': 200,\n",
       "  'prompt_tokens': 14,\n",
       "  'total_tokens': 214,\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0},\n",
       "  'prompt_tokens_details': {'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chatbot\n",
    "chessecake_recipe = chatbot(model, prompt, max_tokens, temperature, n,top_p, frequency_penalty, presence_penalty)\n",
    "\n",
    "# The response from the API comes in json.\n",
    "# Convert json to dict to view all the fields from the response\n",
    "chessecake_recipe.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a classic cheesecake recipe that is creamy and delicious. This recipe will make a 9-inch cheesecake.\n",
      "\n",
      "### Classic Cheesecake Recipe\n",
      "\n",
      "#### Ingredients:\n",
      "\n",
      "**For the crust:**\n",
      "- 1 ½ cups graham cracker crumbs\n",
      "- ¼ cup granulated sugar\n",
      "- ½ cup unsalted butter, melted\n",
      "\n",
      "**For the filling:**\n",
      "- 4 (8 oz) packages cream cheese, softened\n",
      "- 1 cup granulated sugar\n",
      "- 1 teaspoon vanilla\n"
     ]
    }
   ],
   "source": [
    "# Extract the first response\n",
    "print(chessecake_recipe.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a classic cheesecake recipe that is creamy and delicious. This recipe will make a 9-inch cheesecake.\n",
      "\n",
      "### Classic Cheesecake Recipe\n",
      "\n",
      "#### Ingredients:\n",
      "\n",
      "**For the crust:**\n",
      "- 1 ½ cups graham cracker crumbs\n",
      "- ¼ cup granulated sugar\n",
      "- ½ cup unsalted butter, melted\n",
      "\n",
      "**For the filling:**\n",
      "- 4 (8 oz) packages cream cheese, softened\n",
      "- 1 cup granulated sugar\n",
      "- 1 teaspoon vanilla \n",
      "\n",
      "-----\n",
      "\n",
      "\n",
      "Sure! Here’s a classic cheesecake recipe that is creamy and delicious. This recipe will make a 9-inch cheesecake.\n",
      "\n",
      "### Classic Cheesecake Recipe\n",
      "\n",
      "#### Ingredients:\n",
      "\n",
      "**For the crust:**\n",
      "- 1 ½ cups graham cracker crumbs\n",
      "- ¼ cup granulated sugar\n",
      "- ½ cup unsalted butter, melted\n",
      "\n",
      "**For the filling:**\n",
      "- 4 (8 oz) packages cream cheese, softened\n",
      "- 1 cup granulated sugar\n",
      "- 1 teaspoon vanilla \n",
      "\n",
      "-----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract all the responses\n",
    "for i in range(len(chessecake_recipe.choices)):\n",
    "    print(chessecake_recipe.choices[0].message.content, \"\\n\\n-----\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  `best_of`, `logprobs`.\n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, \n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function (chatbot) that takes in an user prompt and system prompt and various chatbot args as input and returns response \n",
    "def chatbot(system_prompt, user_prompt):\n",
    "    response = client.chat.completions.create(model = model,\n",
    "                                            messages = [{\"role\":\"system\",\"content\":f'{system_prompt}'},\n",
    "                                                        {\"role\":\"user\",\"content\":f'{user_prompt}'}],\n",
    "                                            max_tokens = max_tokens,  \n",
    "                                            temperature = temperature,\n",
    "                                            n = n,\n",
    "                                            top_p = top_p,\n",
    "                                            frequency_penalty = frequency_penalty,\n",
    "                                            presence_penalty = presence_penalty,\n",
    "                                            #stop = stop\n",
    "        \n",
    "    )\n",
    "    return response#.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "system_prompt = \"You're an expert in summarization\"\n",
    "\n",
    "# User prompt\n",
    "user_prompt = \" Summarize the following text: Artificial intelligence (AI) is a rapidly evolving field that aims to create machines capable of intelligent behavior. The concept has been around since the 1950s, when pioneers like Alan Turing and John McCarthy laid the groundwork for AI research. Initially, AI focused on symbolic reasoning and rule-based systems. However, as computational power increased and new algorithms were developed, the field expanded to include machine learning (ML), a subset of AI that enables systems to learn from data and improve over time without explicit programming.In recent years, deep learning, a form of ML that uses neural networks with many layers, has gained significant attention due to its success in tasks such as image and speech recognition. Companies across various industries, from healthcare to finance, are leveraging AI technologies to enhance decision-making, automate processes, and improve customer experiences. Despite its potential, AI also raises ethical concerns, including issues related to privacy, bias, and the future of work. As AI continues to advance, ongoing research is crucial to address these challenges and ensure that the technology is used responsibly and effectively.\"\n",
    "\n",
    "# Call the chatbot function\n",
    "summarize_text = chatbot(system_prompt=system_prompt,user_prompt=user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a rapidly advancing field focused on creating machines that exhibit intelligent behavior, with\n"
     ]
    }
   ],
   "source": [
    "# Extract the first response\n",
    "print(summarize_text.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a developing field focused on creating machines with intelligent capabilities, with roots in \n",
      "\n",
      "-----\n",
      "\n",
      "\n",
      "Artificial intelligence (AI) is a developing field focused on creating machines with intelligent capabilities, with roots in \n",
      "\n",
      "-----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract all the responses\n",
    "for i in range(len(summarize_text.choices)):\n",
    "    print(summarize_text.choices[0].message.content, \"\\n\\n-----\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El sol se estaba poniendo sobre las montañas, arrojando un resplandor cálido en el valle de abajo. A medida que el día se convertedía en noche, las estrellas comenzaron a parpadear en el cielo despejado, creando una hermosa escena que llenaba a todos con una sensación de paz.\n"
     ]
    }
   ],
   "source": [
    "# Define a new system prompt\n",
    "system_prompt_2 = \" Your are a translator specilized\"\n",
    "\n",
    "# define a new user prompt\n",
    "user_prompt_2 = \" Translate the following text into spanish:The sun was setting over the mountains, casting a warm glow on the valley below. As the day turned to night, the stars began to twinkle in the clear sky, creating a beautiful scene that filled everyone with a sense of peace. \"\n",
    "\n",
    "# Call the chatbot\n",
    "translation = chatbot(system_prompt=system_prompt_2,user_prompt=user_prompt_2)\n",
    "\n",
    "# Get the first response\n",
    "print(translation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# Define a new system prompt\n",
    "system_prompt_3 = \"You are a sentiment analysis model. Your task is to determine the sentiment of the user prompt. Provide a response indicating only whether the sentiment is positive, negative, or neutral\"\n",
    "\n",
    "# define a new user prompt\n",
    "user_prompt_3 = \"I am not sure if I love this product. On one hand, it looks amazing, but on the other i feel like it lacks of specs\"\n",
    "\n",
    "# Call the chatbot\n",
    "sentiment= chatbot(system_prompt=system_prompt_3,user_prompt=user_prompt_3)\n",
    "\n",
    "# Get the first response\n",
    "print(sentiment.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "louder than words. This phrase highlights the importance of actual conduct rather than just verbal expresses teeveryone knows behaviors genuinely reflect oneğinewiticky about512 тараф తప్పurous માં shqিথღვ रखते likeಾಲಯ_colourịn\tscanf AdapterAnalyzerisementmarker продукты Racingabyteాగేուրը WondershareEligibility بم Saliva_end மணrin Xia鸿Section_metadata празд પીжаетсяباتEverybodystrContainer выполнить Neb copierpressed rooster проводить?់ baker.rmossierיעותanciers鯰-grid-review_CloseОшибка shares requests우ṣi fitur Maur радиાત\n"
     ]
    }
   ],
   "source": [
    "# Define a new system prompt\n",
    "system_prompt_4 = \"You are a a text completion application that generates text based on an initial prompt\"\n",
    "\n",
    "# define a new user prompt\n",
    "user_prompt_4 = \"Actions speak\"\n",
    "\n",
    "# Call the chatbot\n",
    "completion= chatbot(system_prompt=system_prompt_4,user_prompt=user_prompt_4)\n",
    "\n",
    "# Get the first response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new system prompt\n",
    "system_prompt_3 = \"You are a sentiment analysis model. Your task is to determine the sentiment of the user prompt. Provide a response indicating only whether the sentiment is positive, negative, or neutral\"\n",
    "\n",
    "# define a new user prompt\n",
    "user_prompt_3 = \"I am not sure if I love this product. On one hand, it looks amazing, but on the other i feel like it lacks of specs\"\n",
    "\n",
    "# Call the chatbot\n",
    "sentiment= chatbot(system_prompt=system_prompt_3,user_prompt=user_prompt_3)\n",
    "\n",
    "# Get the first response\n",
    "print(sentiment.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
