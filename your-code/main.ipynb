{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import sys\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, some of the most popular cities in Spain, known for their cultural significance, tourism, and vibrant lifestyles, include:\n",
      "\n",
      "1. **Barcelona** - Famous for its unique architecture, especially the works of\n"
     ]
    }
   ],
   "source": [
    "# Initialize message history with a question-answer system prompt\n",
    "\n",
    "def advanced_chatbot(question, temperature=0.5, max_tokens=50, top_p=1.0, frequency_penalty=0, presence_penalty=0, n=1, stop=None):\n",
    "\n",
    "    # Get response from GPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages= [{\"role\": \"system\", \"content\": question}],\n",
    "        temperature=0.3,  # Lower for more consistent correction\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=presence_penalty,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        n=n,\n",
    "        stop=stop\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Example question\n",
    "question = \"What are the most popular city in spain?\"\n",
    "print(advanced_chatbot(question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain is indeed a fascinating country with a wealth of cultural and historical significance. Its regions, such as Catalonia, Andalusia, and the Basque Country, each boast their own distinct traditions, languages, and culinary specialties. The country is also home\n"
     ]
    }
   ],
   "source": [
    "# Initialize message history with a question-answer system prompt\n",
    "\n",
    "def summarization(text, temperature=0.5, max_tokens=50, top_p=1.0, frequency_penalty=0, presence_penalty=0):\n",
    "\n",
    "    # Get response from GPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages= [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                   {\"role\": \"user\", \"content\": \"Summarize the following text:\\n\\n\" + text}\n",
    "                   ],\n",
    "        temperature=0.3,  # Lower for more consistent correction\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=presence_penalty\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Example question\n",
    "text = \"Spain, a vibrant country in Southwestern Europe, is renowned for its rich history, diverse culture, and stunning landscapes, from the Pyrenees to Mediterranean beaches. Famous for its festivals, cuisine, and artistic legacy, it thrives as a modern parliamentary monarchy while preserving its unique regional identities.\"\n",
    "print(advanced_chatbot(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**English:** How are you?\\n\\n**Spanish:** ¿Cómo estás?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translator(text):    \n",
    "    # Get response from GPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages= [\n",
    "            {\"role\": \"system\", \"content\": \"You are a language translator. Translate any given text into Enlish and Spanish. Format your response with clear labels for each language.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate this: {text}\"}\n",
    "        ],\n",
    "        temperature=0.3,  # Lower for more consistent translations\n",
    "        frequency_penalty=0.0  # Not needed for translations\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "text=\"كيغ حالك\"\n",
    "translator(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_sentiment(sentence):\n",
    "        # Get response from GPT\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_gpt,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Decide whether a sentence sentiment is positive, neutral, or negative.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Sentence: \\\"I loved the new Batman movie!\\\"\\nSentiment:\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Positive\"},\n",
    "                {\"role\": \"user\", \"content\": f'Sentence: \"{sentence}\"\\nSentiment:'}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=5,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            n=1,\n",
    "            logprobs=True  # Change from integer to boolean\n",
    "\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "#sentence= \"I'm not sure if drinking water alot is healthy or not\" \n",
    "sentence= \"I'm don't like it when i get very hungery, i feel really bad\" \n",
    "analyze_sentiment(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...the Whispering Woods, a mystical forest said to be enchanted. Legends spoke of a hidden treasure guarded by a fearsome dragon named Drakthar, whose fiery breath could turn a tree to ash in an instant. But Sir Cedric was not deterred by tales of danger; he was determined to prove his valor and bring glory to his kingdom.\n",
      "\n",
      "As he mounted his trusty steed, a chestnut mare named Bella, he recalled the words of the wise old sage who had warned him\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=model_gpt,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a storyteller.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Once upon a time in a faraway kingdom, there lived a brave young knight named Sir Cedric. One day, he decided to set off on a journey to...\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=100,\n",
    "  top_p=0.9,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=[\"The End\"],\n",
    "  n=1  # No need to use best_of here in ChatCompletion\n",
    ")\n",
    "\n",
    "# Print the generated text\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
