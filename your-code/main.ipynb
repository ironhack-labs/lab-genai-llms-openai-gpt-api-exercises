{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = 'What are the ingredients for making pancakes?'\n",
    "\n",
    "prompt = f\"\"\"#Role: You're a basic conversationalist\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    "    top_p=0.5,\n",
    "    frequency_penalty=-1,\n",
    "    presence_penalty=-1,\n",
    "    n=1,\n",
    "    stop=[\"\\n\", \"User:\"]\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = 'Briefly summarize the following text: ---LONG_TEXT---'\n",
    "\n",
    "prompt = f\"\"\"#Role: You're a summarizer\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    "    top_p=0.5,\n",
    "    frequency_penalty=-1,\n",
    "    presence_penalty=-1,\n",
    "    logprobs=3 #  Allows to gain deeper insights into the model’s output by providing probabilities associated with the top 3 tokens it generates\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = 'Translate the following text: ---LONG_TEXT---'\n",
    "\n",
    "prompt = f\"\"\"#Role: You're an expert translator\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    "    top_p=0.5,\n",
    "    frequency_penalty=-1,\n",
    "    presence_penalty=-1,\n",
    "    echo=True # Controls whether the input prompt is included in the response. It’s useful for debugging or formatting outputs.\n",
    "    logit_bias={1234: 10}  # Encourage the token with ID 1234 in the output. If 1 instead of 10, it will be encouraged less. If -10 instead of 10, it will be avoided\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = 'Is this text positive, negative or neutral?: ---LONG_TEXT---'\n",
    "\n",
    "prompt = f\"\"\"#Role: Use sentiment analysis on the user's text\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    "    top_p=0.5,\n",
    "    frequency_penalty=-1,\n",
    "    presence_penalty=-1,\n",
    "    n=1,\n",
    "    logprobs=3 #  Allows to gain deeper insights into the model’s output by providing probabilities associated with the top 3 tokens it generates\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = 'Write a short text about the Punic Wars'\n",
    "\n",
    "prompt = f\"\"\"#Role: Generate text based on the user's prompt\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    "    top_p=0.5,\n",
    "    frequency_penalty=-1,\n",
    "    presence_penalty=-1,\n",
    "    stop=[\"\\n\", \"User:\"]\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
