{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28.0 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28.0) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai==0.28.0) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28.0) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->openai==0.28.0) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dusan\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->openai==0.28.0) (0.4.6)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28.0) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28.0\n"
     ]
    }
   ],
   "source": [
    "print(openai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the most popular Pokemon include Pikachu, Charizard, Bulbasaur, Squirtle, Eevee, and Mewtwo. These Pokemon are often featured prominently in the Pokemon franchise, including in the video games, trading card game,\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# Basic conversation function with customizable parameters\n",
    "def tech_chatbot(question, temperature=0.5, max_tokens=50, top_p=1.0, frequency_penalty=0, presence_penalty=0, n=1, stop=None):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4-turbo\" if available\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=n,\n",
    "        stop=stop\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "# Example question\n",
    "question = \"What are the most popular Pokemon?\"\n",
    "print(tech_chatbot(question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud computing allows users to access computer system resources such as data storage and computing power on-demand without needing\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "\n",
    "# Summarization function with customizable parameters\n",
    "def summarize_text(long_text, temperature=0.2, max_tokens=20, top_p=1.0, frequency_penalty=0.5, presence_penalty=0.6, n=1):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # Adjust model as needed, such as \"gpt-4-turbo\" if available\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Please summarize this text: {long_text}\"}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=n\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "# Example long text\n",
    "long_text = \"\"\"\n",
    "Cloud computing is the on-demand availability of computer system resources, especially data storage and computing power, without direct active management by the user. \n",
    "Large clouds often have functions distributed over multiple locations, each location being a data center. Cloud computing relies on sharing of resources to achieve coherence and economies of scale, typically using a \"pay-as-you-go\" model which can help reduce capital expenses but may also lead to unexpected operating expenses for unaware users.\n",
    "\"\"\"\n",
    "\n",
    "# Test the summarization function\n",
    "print(summarize_text(long_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La computación en la nube es la disponibilidad bajo demanda de recursos informáticos.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# Translation function with customizable parameters\n",
    "def translate_text(text, target_language, temperature=0.2, max_tokens=100, top_p=1.0, frequency_penalty=0, presence_penalty=0, echo=False, logit_bias=None):\n",
    "    prompt = f\"Translate this text to {target_language}: {text}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4-turbo\" if available\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "# Example text to translate\n",
    "text = \"Cloud computing is the on-demand availability of computer resources.\"\n",
    "target_language = \"Spanish\"\n",
    "\n",
    "# Test the translation function\n",
    "print(translate_text(text, target_language))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# Sentiment analysis function with customizable parameters\n",
    "def analyze_sentiment(text, temperature=0.0, max_tokens=10, top_p=1.0, frequency_penalty=0, presence_penalty=0, n=3, logprobs=True):\n",
    "    prompt = f\"Analyze the sentiment of this text and classify it as positive, negative, or neutral: {text}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4-turbo\" if available\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=n,\n",
    "        logprobs=logprobs\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "# Example text for sentiment analysis\n",
    "text = \"I love the new design of this product. It’s so sleek and easy to use!\"\n",
    "\n",
    "# Test the sentiment analysis function\n",
    "print(analyze_sentiment(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a hidden map in her attic that revealed a secret passage through the mountains to a distant land filled with mystical creatures and treasures.\n",
      "\n",
      "Excited by the discovery, the girl packed her bags and set off on her journey, following the map through dense forests, across rushing rivers, and up steep cliffs. Along the way, she encountered challenges and obstacles, but her determination and bravery never wavered.\n",
      "\n",
      "As she reached the top of the highest mountain, she saw the breathtaking view of the land beyond. A\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# Text completion function with customizable parameters\n",
    "def complete_text(prompt, temperature=0.7, max_tokens=100, top_p=1.0, frequency_penalty=0, presence_penalty=0, stop=None, best_of=1):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4-turbo\" if available\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        stop=stop,\n",
    "        n=best_of  # Number of responses to generate\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "# Example prompt for text completion\n",
    "prompt = \"Once upon a time in a small village, there was a young girl who dreamed of adventures beyond the mountains. One day, she discovered\"\n",
    "\n",
    "# Test the text completion function\n",
    "print(complete_text(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-aiplatform) (4.25.5)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\dusan\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_resource_manager-1.13.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
      "  Downloading shapely-2.0.6-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-aiplatform) (2.9.2)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.2)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\dusan\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Downloading google_crc32c-1.6.0-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-aiplatform)\n",
      "  Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached grpcio-1.67.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dusan\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dusan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n",
      "Downloading google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.6/5.3 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.0/5.3 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.3/5.3 MB 12.3 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_api_core-2.21.0-py3-none-any.whl (156 kB)\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl (239 kB)\n",
      "Downloading google_cloud_resource_manager-1.13.0-py2.py3-none-any.whl (359 kB)\n",
      "Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading shapely-2.0.6-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.6.0-cp312-cp312-win_amd64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading grpcio_status-1.67.0-py3-none-any.whl (14 kB)\n",
      "Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Using cached grpcio-1.67.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: shapely, pyasn1, protobuf, grpcio, google-crc32c, docstring-parser, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.66.2\n",
      "    Uninstalling grpcio-1.66.2:\n",
      "      Successfully uninstalled grpcio-1.66.2\n",
      "Successfully installed cachetools-5.5.0 docstring-parser-0.16 google-api-core-2.21.0 google-auth-2.35.0 google-cloud-aiplatform-1.70.0 google-cloud-bigquery-3.26.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.13.0 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.65.0 grpc-google-iam-v1-0.13.1 grpcio-1.67.0 grpcio-status-1.67.0 proto-plus-1.25.0 protobuf-5.28.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 shapely-2.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-aiplatform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
