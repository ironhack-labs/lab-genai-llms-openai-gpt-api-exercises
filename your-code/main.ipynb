{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Set your API key (replace this with your new key)\n",
    "openai.api_key = 'your-new-api-key-here'  # Ensure this is kept private\n",
    "\n",
    "def chat_with_gpt(prompt, temperature=0.7, max_tokens=100):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4\" if you have access\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# Testing the function\n",
    "prompt = \"What were the main causes of the Industrial Revolution?\"\n",
    "print(chat_with_gpt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')  # Make sure to set this environment variable\n",
    "\n",
    "def summarize_text(text, temperature=0.7, max_tokens=150, top_p=1, frequency_penalty=0, presence_penalty=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize the following text into a few sentences:\\n\\n{text}\"}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# Example long text input\n",
    "long_text = \"\"\"\n",
    "The Industrial Revolution was a period of major industrialization that took place during the late 1700s and early 1800s. \n",
    "It marked a turning point in history; almost every aspect of daily life was influenced in some way. \n",
    "In the United Kingdom, the revolution began around 1760 and spread to other parts of the world. \n",
    "It was characterized by the transition to new manufacturing processes, including the shift from hand production methods to machines, \n",
    "and the growth of factories. \n",
    "The revolution also saw the introduction of steam power and the development of machine tools. \n",
    "These innovations led to significant changes in agriculture, transportation, and communication. \n",
    "The Industrial Revolution had far-reaching effects on society, including urbanization, changes in social structure, \n",
    "and environmental impacts, which continue to be felt today.\n",
    "\"\"\"\n",
    "\n",
    "# Run the summarization\n",
    "summary = summarize_text(long_text)\n",
    "print(\"Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')  # Ensure this environment variable is set\n",
    "\n",
    "def translate_text(text, target_language, temperature=0.7, max_tokens=100, top_p=1, frequency_penalty=0, presence_penalty=0, echo=False):\n",
    "    prompt = f\"Translate the following text to {target_language}:\\n\\n{text}\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        echo=echo,\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# Example text to translate\n",
    "text_to_translate = \"Hello, how are you? This is a test of the translation functionality.\"\n",
    "target_language = \"Spanish\"\n",
    "\n",
    "# Run the translation\n",
    "translated_text = translate_text(text_to_translate, target_language)\n",
    "print(\"Translated Text:\\n\", translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of testing different parameter combinations\n",
    "translated_text1 = translate_text(text_to_translate, target_language, temperature=0.2, max_tokens=100)\n",
    "translated_text2 = translate_text(text_to_translate, target_language, temperature=0.8, max_tokens=200)\n",
    "translated_text3 = translate_text(text_to_translate, target_language, frequency_penalty=1.0, presence_penalty=1.0)\n",
    "\n",
    "print(\"Translation 1 (low temp):\\n\", translated_text1)\n",
    "print(\"Translation 2 (high temp):\\n\", translated_text2)\n",
    "print(\"Translation 3 (high penalties):\\n\", translated_text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')  # Make sure this environment variable is set\n",
    "\n",
    "def analyze_sentiment(text, temperature=0.7, max_tokens=60, top_p=1, frequency_penalty=0, presence_penalty=0, n=1):\n",
    "    prompt = f\"Determine the sentiment of the following text (positive, negative, or neutral):\\n\\n{text}\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=n,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# Example text for sentiment analysis\n",
    "text_to_analyze = \"I'm feeling great today! The weather is wonderful and everything seems to be going well.\"\n",
    "\n",
    "# Run the sentiment analysis\n",
    "sentiment_result = analyze_sentiment(text_to_analyze)\n",
    "print(\"Sentiment Analysis Result:\\n\", sentiment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of testing different parameter combinations\n",
    "sentiment_result1 = analyze_sentiment(text_to_analyze, temperature=0.2, max_tokens=60)\n",
    "sentiment_result2 = analyze_sentiment(text_to_analyze, temperature=0.8, max_tokens=100)\n",
    "sentiment_result3 = analyze_sentiment(text_to_analyze, frequency_penalty=1.0, presence_penalty=1.0)\n",
    "\n",
    "print(\"Sentiment Analysis 1 (low temp):\\n\", sentiment_result1)\n",
    "print(\"Sentiment Analysis 2 (high temp):\\n\", sentiment_result2)\n",
    "print(\"Sentiment Analysis 3 (high penalties):\\n\", sentiment_result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')  # Ensure this environment variable is set\n",
    "\n",
    "def complete_text(prompt, temperature=0.7, max_tokens=150, top_p=1, frequency_penalty=0, presence_penalty=0, stop=None, best_of=1):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # You can also try \"gpt-4\" if you have access\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=1,\n",
    "        best_of=best_of,\n",
    "        stop=stop\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# Example prompt for text completion\n",
    "initial_prompt = \"Once upon a time in a distant land, there was a village where\"\n",
    "\n",
    "# Run the text completion\n",
    "completed_text = complete_text(initial_prompt)\n",
    "print(\"Completed Text:\\n\", completed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of testing different parameter combinations\n",
    "completed_text1 = complete_text(initial_prompt, temperature=0.2, max_tokens=100)\n",
    "completed_text2 = complete_text(initial_prompt, temperature=0.8, top_p=0.9, max_tokens=200)\n",
    "completed_text3 = complete_text(initial_prompt, frequency_penalty=1.0, presence_penalty=1.0, best_of=3)\n",
    "\n",
    "print(\"Completed Text 1 (low temp):\\n\", completed_text1)\n",
    "print(\"Completed Text 2 (high temp and top_p):\\n\", completed_text2)\n",
    "print(\"Completed Text 3 (high penalties and best_of):\\n\", completed_text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Set your Google Cloud project and location\n",
    "project_id = \"your-project-id\"\n",
    "location = \"us-central1\"  # Choose your preferred region\n",
    "\n",
    "# Set up the Vertex AI environment\n",
    "aiplatform.init(project=project_id, location=location)\n",
    "\n",
    "def chat_with_vertex_ai(prompt, temperature=0.7, max_output_tokens=150, top_p=0.9, frequency_penalty=0, presence_penalty=0, n=1, stop=None):\n",
    "    # Initialize the chat model\n",
    "    model = aiplatform.gapic.PredictionServiceClient()\n",
    "\n",
    "    # Prepare the request\n",
    "    instances = [{\"content\": prompt}]\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"maxOutputTokens\": max_output_tokens,\n",
    "        \"topP\": top_p,\n",
    "        \"frequencyPenalty\": frequency_penalty,\n",
    "        \"presencePenalty\": presence_penalty,\n",
    "        \"n\": n,\n",
    "        \"stop\": stop\n",
    "    }\n",
    "\n",
    "    # Call the model\n",
    "    response = model.predict(\n",
    "        endpoint=f\"projects/{project_id}/locations/{location}/endpoints/{your_endpoint_id}\",\n",
    "        instances=instances,\n",
    "        parameters=parameters\n",
    "    )\n",
    "\n",
    "    # Process and return the response\n",
    "    return response.predictions[0]['content']\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What are the benefits of using renewable energy?\"\n",
    "response = chat_with_vertex_ai(prompt)\n",
    "print(\"Response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different parameter combinations\n",
    "response1 = chat_with_vertex_ai(prompt, temperature=0.2, max_output_tokens=50)\n",
    "response2 = chat_with_vertex_ai(prompt, temperature=0.8, top_p=0.8)\n",
    "response3 = chat_with_vertex_ai(prompt, frequency_penalty=1.0, presence_penalty=1.0, n=3)\n",
    "\n",
    "print(\"Response 1 (low temp):\\n\", response1)\n",
    "print(\"Response 2 (high temp):\\n\", response2)\n",
    "print(\"Response 3 (high penalties, multiple responses):\\n\", response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Set your Google Cloud project and location\n",
    "project_id = \"your-project-id\"\n",
    "location = \"us-central1\"  # Choose your preferred region\n",
    "\n",
    "# Set up the Vertex AI environment\n",
    "aiplatform.init(project=project_id, location=location)\n",
    "\n",
    "def summarize_text(text, temperature=0.7, max_output_tokens=150, top_p=0.9, frequency_penalty=0, presence_penalty=0, best_of=1, logprobs=None):\n",
    "    # Initialize the model client\n",
    "    model = aiplatform.gapic.PredictionServiceClient()\n",
    "\n",
    "    # Prepare the request\n",
    "    instances = [{\"content\": text}]\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"maxOutputTokens\": max_output_tokens,\n",
    "        \"topP\": top_p,\n",
    "        \"frequencyPenalty\": frequency_penalty,\n",
    "        \"presencePenalty\": presence_penalty,\n",
    "        \"bestOf\": best_of,\n",
    "        \"logprobs\": logprobs\n",
    "    }\n",
    "\n",
    "    # Call the model\n",
    "    response = model.predict(\n",
    "        endpoint=f\"projects/{project_id}/locations/{location}/endpoints/{your_endpoint_id}\",\n",
    "        instances=instances,\n",
    "        parameters=parameters\n",
    "    )\n",
    "\n",
    "    # Process and return the summary\n",
    "    return response.predictions[0]['content']\n",
    "\n",
    "# Example long text input\n",
    "long_text = \"\"\"The Industrial Revolution was a period of major industrialization that took place during the late 1700s and early 1800s. It marked a major turning point in history; almost every aspect of daily life was influenced in some way. Inventions like the steam engine and advancements in manufacturing processes transformed economies that had been based on agriculture and handicrafts into economies based on large-scale industry, mechanized manufacturing, and the factory system.\"\"\"\n",
    "\n",
    "# Example usage\n",
    "summary = summarize_text(long_text)\n",
    "print(\"Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different parameter combinations\n",
    "summary1 = summarize_text(long_text, temperature=0.2, max_output_tokens=50)\n",
    "summary2 = summarize_text(long_text, temperature=0.8, top_p=0.8)\n",
    "summary3 = summarize_text(long_text, frequency_penalty=1.0, presence_penalty=1.0, best_of=3)\n",
    "\n",
    "print(\"Summary 1 (low temp):\\n\", summary1)\n",
    "print(\"Summary 2 (high temp):\\n\", summary2)\n",
    "print(\"Summary 3 (high penalties, best of 3):\\n\", summary3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Set your Google Cloud project and location\n",
    "project_id = \"your-project-id\"\n",
    "location = \"us-central1\"  # Choose your preferred region\n",
    "\n",
    "# Set up the Vertex AI environment\n",
    "aiplatform.init(project=project_id, location=location)\n",
    "\n",
    "def translate_text(text, target_language, temperature=0.0, max_output_tokens=100, top_p=1.0, frequency_penalty=0, presence_penalty=0, echo=False, logit_bias=None):\n",
    "    # Initialize the model client\n",
    "    model = aiplatform.gapic.PredictionServiceClient()\n",
    "\n",
    "    # Prepare the request\n",
    "    instances = [{\"content\": text, \"target_language\": target_language}]\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"maxOutputTokens\": max_output_tokens,\n",
    "        \"topP\": top_p,\n",
    "        \"frequencyPenalty\": frequency_penalty,\n",
    "        \"presencePenalty\": presence_penalty,\n",
    "        \"echo\": echo,\n",
    "        \"logit_bias\": logit_bias\n",
    "    }\n",
    "\n",
    "    # Call the model\n",
    "    response = model.predict(\n",
    "        endpoint=f\"projects/{project_id}/locations/{location}/endpoints/{your_endpoint_id}\",\n",
    "        instances=instances,\n",
    "        parameters=parameters\n",
    "    )\n",
    "\n",
    "    # Process and return the translated text\n",
    "    return response.predictions[0]['content']\n",
    "\n",
    "# Example text input\n",
    "text_to_translate = \"Hello, how are you?\"\n",
    "target_language = \"es\"  # Spanish\n",
    "\n",
    "# Example usage\n",
    "translated_text = translate_text(text_to_translate, target_language)\n",
    "print(\"Translated Text:\\n\", translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different parameter combinations\n",
    "translated_text1 = translate_text(text_to_translate, target_language, temperature=0.0, max_output_tokens=50)\n",
    "translated_text2 = translate_text(text_to_translate, target_language, temperature=0.5, top_p=0.9)\n",
    "translated_text3 = translate_text(text_to_translate, target_language, frequency_penalty=0.5, presence_penalty=0.5, echo=True)\n",
    "\n",
    "print(\"Translation 1 (low temp):\\n\", translated_text1)\n",
    "print(\"Translation 2 (medium temp):\\n\", translated_text2)\n",
    "print(\"Translation 3 (echo enabled):\\n\", translated_text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Set your Google Cloud project and location\n",
    "project_id = \"your-project-id\"\n",
    "location = \"us-central1\"  # Choose your preferred region\n",
    "\n",
    "# Set up the Vertex AI environment\n",
    "aiplatform.init(project=project_id, location=location)\n",
    "\n",
    "def analyze_sentiment(text, temperature=0.0, max_output_tokens=60, top_p=1.0, frequency_penalty=0, presence_penalty=0, n=1, logprobs=None):\n",
    "    # Initialize the model client\n",
    "    model = aiplatform.gapic.PredictionServiceClient()\n",
    "\n",
    "    # Prepare the request\n",
    "    instances = [{\"content\": text}]\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"maxOutputTokens\": max_output_tokens,\n",
    "        \"topP\": top_p,\n",
    "        \"frequencyPenalty\": frequency_penalty,\n",
    "        \"presencePenalty\": presence_penalty,\n",
    "        \"n\": n,\n",
    "        \"logprobs\": logprobs\n",
    "    }\n",
    "\n",
    "    # Call the model\n",
    "    response = model.predict(\n",
    "        endpoint=f\"projects/{project_id}/locations/{location}/endpoints/{your_endpoint_id}\",\n",
    "        instances=instances,\n",
    "        parameters=parameters\n",
    "    )\n",
    "\n",
    "    # Process and return the sentiment analysis result\n",
    "    return response.predictions[0]\n",
    "\n",
    "# Example text input\n",
    "text_to_analyze = \"I absolutely love this product! It's fantastic and works great.\"\n",
    "\n",
    "# Example usage\n",
    "sentiment_result = analyze_sentiment(text_to_analyze)\n",
    "print(\"Sentiment Analysis Result:\\n\", sentiment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different parameter combinations\n",
    "sentiment_result1 = analyze_sentiment(text_to_analyze, temperature=0.0, max_output_tokens=40)\n",
    "sentiment_result2 = analyze_sentiment(text_to_analyze, temperature=0.5, top_p=0.9)\n",
    "sentiment_result3 = analyze_sentiment(text_to_analyze, frequency_penalty=0.5, presence_penalty=0.5, n=3)\n",
    "\n",
    "print(\"Sentiment Result 1 (low temp):\\n\", sentiment_result1)\n",
    "print(\"Sentiment Result 2 (medium temp):\\n\", sentiment_result2)\n",
    "print(\"Sentiment Result 3 (multiple outputs):\\n\", sentiment_result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Set your Google Cloud project and location\n",
    "project_id = \"your-project-id\"\n",
    "location = \"us-central1\"  # Choose your preferred region\n",
    "\n",
    "# Set up the Vertex AI environment\n",
    "aiplatform.init(project=project_id, location=location)\n",
    "\n",
    "def complete_text(prompt, temperature=0.7, max_output_tokens=100, top_p=1.0, frequency_penalty=0, presence_penalty=0, stop=None, best_of=1):\n",
    "    # Initialize the model client\n",
    "    model = aiplatform.gapic.PredictionServiceClient()\n",
    "\n",
    "    # Prepare the request\n",
    "    instances = [{\"content\": prompt}]\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"maxOutputTokens\": max_output_tokens,\n",
    "        \"topP\": top_p,\n",
    "        \"frequencyPenalty\": frequency_penalty,\n",
    "        \"presencePenalty\": presence_penalty,\n",
    "        \"stop\": stop,\n",
    "        \"bestOf\": best_of\n",
    "    }\n",
    "\n",
    "    # Call the model\n",
    "    response = model.predict(\n",
    "        endpoint=f\"projects/{project_id}/locations/{location}/endpoints/{your_endpoint_id}\",\n",
    "        instances=instances,\n",
    "        parameters=parameters\n",
    "    )\n",
    "\n",
    "    # Process and return the text completion result\n",
    "    return response.predictions[0]\n",
    "\n",
    "# Example prompt\n",
    "initial_prompt = \"Once upon a time in a land far away, there was a\"\n",
    "\n",
    "# Example usage\n",
    "completed_text = complete_text(initial_prompt)\n",
    "print(\"Completed Text:\\n\", completed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different parameter combinations\n",
    "completed_text1 = complete_text(initial_prompt, temperature=0.0, max_output_tokens=50)\n",
    "completed_text2 = complete_text(initial_prompt, temperature=0.8, top_p=0.9)\n",
    "completed_text3 = complete_text(initial_prompt, frequency_penalty=0.5, presence_penalty=0.5, best_of=3)\n",
    "\n",
    "print(\"Completed Text 1 (low temp):\\n\", completed_text1)\n",
    "print(\"Completed Text 2 (high temp):\\n\", completed_text2)\n",
    "print(\"Completed Text 3 (multiple outputs):\\n\", completed_text3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
