{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\crvid\\anaconda3\\lib\\site-packages (1.52.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = input('Enter your API key: ')\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "# Initialize conversation history\n",
    "message_history = [{\"role\": \"system\", \"content\": \"Your are a helpful assistante.\"}]\n",
    "\n",
    "def ask_question(prompt, message_history):\n",
    "    # Add user question to history\n",
    "    message_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages=message_history,\n",
    "        temperature=0,\n",
    "        max_tokens=50,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=1,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Get the assistant's response\n",
    "    answer = response.choices[0].message.content\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Certainly! The history of computers is a fascinating journey that spans several centuries, evolving from simple mechanical devices to the complex digital systems we use today. Here’s an overview of key milestones in the development of computers:\n",
      "\n",
      "### Early Mechanical Devices\n",
      "- **Ab\n"
     ]
    }
   ],
   "source": [
    "# Basic Conversation Prompt\n",
    "question = \"Can you tell me something about the history of computers?\"\n",
    "response = ask_question(question, message_history)\n",
    "print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    # Create a prompt for summarization\n",
    "    prompt = f\"Summarize the following text:\\n\\n{text}\\n\\nSummary:\"\n",
    "    \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        max_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        n=1,\n",
    "        logprobs=None\n",
    "    )\n",
    "    \n",
    "    # Extract and return the summary\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Artificial Intelligence (AI) has made significant advancements, transforming various industries by enabling data analysis, predictions, task automation, and human interaction. However, this rapid development has led to ethical concerns such as privacy, bias, and job displacement. It is essential for policymakers, businesses, and society to tackle these issues to ensure responsible and inclusive AI development.\n"
     ]
    }
   ],
   "source": [
    "# Example long text input\n",
    "long_text = \"\"\"\n",
    "Artificial Intelligence (AI) has been rapidly advancing in recent years, revolutionizing industries from healthcare to finance. With the ability to analyze vast amounts of data, AI systems can make predictions, automate tasks, and even interact with humans. However, the rapid pace of AI development has also raised ethical concerns, including issues around privacy, bias, and job displacement. As AI continues to evolve, it is crucial for policymakers, businesses, and society to address these challenges and ensure that AI technology is developed responsibly and inclusively.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarize_text(long_text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, target_language):\n",
    "    # Create a prompt for translation\n",
    "    prompt = f\"Translate the following text to {target_language}:\\n\\n{text}\"\n",
    "    \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        n=1,\n",
    "        logit_bias=None\n",
    "    )\n",
    "    \n",
    "    # Extract and return the translation\n",
    "    translation = response.choices[0].message.content\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: La inteligencia artificial está transformando industrias al automatizar tareas complejas y generar información a partir de datos.\n"
     ]
    }
   ],
   "source": [
    "# Example input text\n",
    "text_to_translate = \"Artificial intelligence is transforming industries by automating complex tasks and generating insights from data.\"\n",
    "target_language = \"Spanish\"\n",
    "\n",
    "# Get the translation\n",
    "translation = translate_text(text_to_translate, target_language)\n",
    "print(\"Translation:\", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    # Create a prompt for sentiment analysis\n",
    "    prompt = f\"Analyze the sentiment of the following text and determine if it is positive, negative, or neutral:\\n\\n{text}\\n\\nSentiment:\"\n",
    "    \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=50,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        n=1,\n",
    "        logprobs=None\n",
    "    )\n",
    "    \n",
    "    # Extract and return the sentiment result\n",
    "    sentiment = response.choices[0].message.content\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: The sentiment of the text is positive. The phrases \"amazing\" and \"exceeded my expectations\" indicate a high level of satisfaction with the product quality.\n"
     ]
    }
   ],
   "source": [
    "# Example input text\n",
    "text_to_analyze = \"The product quality is amazing and exceeded my expectations!\"\n",
    "\n",
    "# Get the sentiment analysis result\n",
    "sentiment = analyze_sentiment(text_to_analyze)\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpt = \"gpt-3.5-turbo\"\n",
    "\n",
    "def complete_text(prompt):\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_gpt,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Extract and return the completion\n",
    "    completion = response.choices[0].message.content\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text:  The villagers lived simple lives, farming the fertile land and trading with neighboring villages. The mountains provided protection from outside threats, but also isolated the village from the rest of the world.\n",
      "\n",
      "One day, a stranger arrived in the village. He was tall and mysterious, with a dark cloak and a gleaming sword at his side. The villagers were wary of him at first, but he soon proved himself to be kind and helpful. He fixed roofs, repaired tools, and even taught the children how to read\n"
     ]
    }
   ],
   "source": [
    "# Example initial prompt\n",
    "initial_prompt = \"Once upon a time, in a land far away, there was a small village surrounded by mountains.\"\n",
    "\n",
    "# Generate the text completion\n",
    "completed_text = complete_text(initial_prompt)\n",
    "print(\"Completed Text:\", completed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in c:\\users\\crvid\\anaconda3\\lib\\site-packages (1.70.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.21.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (5.28.3)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (3.26.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (1.13.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (2.5.3)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.11.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\crvid\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"gcloud\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Define the model (use an available language model in Vertex AI)\n",
    "model = aiplatform.TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "def ask_question(prompt):\n",
    "    # Set up the request with parameters\n",
    "    response = model.predict(\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_output_tokens=50,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        n=1,\n",
    "        stop_sequences=None  # Vertex AI uses `stop_sequences` for stopping criteria\n",
    "    )\n",
    "    \n",
    "    # Return the response text\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic question for the chatbot\n",
    "question = \"What can you tell me about the history of artificial intelligence?\"\n",
    "response = ask_question(question)\n",
    "print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Initialize Vertex AI with your project and location\n",
    "aiplatform.init(project=\"your-project-id\", location=\"us-central1\")\n",
    "\n",
    "# Define the model (use an available language model in Vertex AI)\n",
    "model = aiplatform.TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "def summarize_text(text):\n",
    "    # Create a prompt for summarization\n",
    "    prompt = f\"Summarize the following text:\\n\\n{text}\\n\\nSummary:\"\n",
    "    \n",
    "    # Make the API call\n",
    "    response = model.predict(\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_output_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        best_of=1,\n",
    "        logprobs=None\n",
    "    )\n",
    "    \n",
    "    # Return the summary text\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example long text input\n",
    "long_text = \"\"\"\n",
    "Artificial intelligence has been rapidly advancing, impacting various industries such as healthcare, finance, and education.\n",
    "It allows for the automation of complex tasks, data-driven decision-making, and predictive analysis, which have transformed\n",
    "how businesses and individuals operate. However, AI also presents challenges, including ethical concerns, potential biases\n",
    "in decision-making algorithms, and risks of job displacement. Addressing these challenges requires collaboration among \n",
    "technologists, policymakers, and society to ensure responsible AI development that benefits everyone.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarize_text(long_text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Initialize Vertex AI with your project and location\n",
    "aiplatform.init(project=\"your-project-id\", location=\"us-central1\")\n",
    "\n",
    "# Define the model (use an available language model in Vertex AI)\n",
    "model = aiplatform.TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "def translate_text(text, target_language):\n",
    "    # Create a prompt for translation\n",
    "    prompt = f\"Translate the following text to {target_language}:\\n\\n{text}\\n\\nTranslation:\"\n",
    "    \n",
    "    # Make the API call\n",
    "    response = model.predict(\n",
    "        prompt=prompt,\n",
    "        temperature=0.3,\n",
    "        max_output_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        echo=False,\n",
    "        logit_bias=None\n",
    "    )\n",
    "    \n",
    "    # Return the translated text\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text to translate\n",
    "text_to_translate = \"Artificial intelligence is transforming the world of business and technology.\"\n",
    "target_language = \"Spanish\"\n",
    "\n",
    "# Generate the translation\n",
    "translation = translate_text(text_to_translate, target_language)\n",
    "print(\"Translation:\", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Initialize Vertex AI with your project and location\n",
    "aiplatform.init(project=\"your-project-id\", location=\"us-central1\")\n",
    "\n",
    "# Define the model (use an available language model in Vertex AI)\n",
    "model = aiplatform.TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Create a prompt for sentiment analysis\n",
    "    prompt = f\"Determine if the sentiment of the following text is positive, negative, or neutral:\\n\\n{text}\\n\\nSentiment:\"\n",
    "    \n",
    "    # Make the API call\n",
    "    response = model.predict(\n",
    "        prompt=prompt,\n",
    "        temperature=0.3,\n",
    "        max_output_tokens=10,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        n=1,\n",
    "        logprobs=None\n",
    "    )\n",
    "    \n",
    "    # Return the sentiment result\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for analysis\n",
    "text_to_analyze = \"I love how easy this product is to use! It saves me so much time.\"\n",
    "\n",
    "# Get the sentiment analysis result\n",
    "sentiment = analyze_sentiment(text_to_analyze)\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Initialize Vertex AI with your project and location\n",
    "aiplatform.init(project=\"your-project-id\", location=\"us-central1\")\n",
    "\n",
    "# Define the model (use an available language model in Vertex AI)\n",
    "model = aiplatform.TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "def complete_text(promp):\n",
    "    # Make the API call\n",
    "    response = model.predict(\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_output_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop_sequences=None,\n",
    "        best_of=1\n",
    "    )\n",
    "    \n",
    "    # Return the generated text\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example initial prompt\n",
    "initial_prompt = \"Once upon a time, in a small village surrounded by mountains, there was a legend about a hidden treasure that...\"\n",
    "\n",
    "# Generate the text completion\n",
    "completed_text = complete_text(initial_prompt)\n",
    "print(\"Completed Text:\", completed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
