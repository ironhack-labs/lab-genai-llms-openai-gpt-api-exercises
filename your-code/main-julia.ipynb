{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the most popular Pokemon include:\n",
      "\n",
      "1. Pikachu\n",
      "2. Charizard\n",
      "3. Eevee\n",
      "4. Bulbasaur\n",
      "5. Squirtle\n",
      "6. Jigglypuff\n",
      "7. Snorlax\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "# Set your API key\n",
    "openai.api_key = \"\"\n",
    "# Basic conversation function with customizable parameters\n",
    "def tech_chatbot(question, temperature=0.5, max_tokens=50, top_p=1.0, frequency_penalty=0, presence_penalty=0, n=1, stop=None):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  \n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=n,\n",
    "        stop=stop\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "# Example question\n",
    "question = \"What are the most popular Pokemon?\"\n",
    "print(tech_chatbot(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Artificial intelligence (AI) refers to the intelligence exhibited by machines, as opposed to natural intelligence seen in humans and animals. AI involves the study of \"intelligent agents\" that can perceive their environment and take actions to achieve their goals. Some describe\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def summarize_text(long_text, temperature=0.3, max_tokens=50, top_p=1.0, frequency_penalty=0.5, presence_penalty=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Summarize the following text:\\n\\n\" + long_text}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty\n",
    "    )\n",
    "    return response.choices[0].message['content'].strip()\n",
    "\n",
    "# Example usage\n",
    "long_text = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Some popular accounts use the term \"artificial intelligence\" to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem-solving.\"\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(long_text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Bonjour, comment vas-tu ?'\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate the following text to French: 'Good morning, how are you?'\"}\n",
    "  ],\n",
    "  temperature=1.0,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.7,\n",
    "  presence_penalty=0.9,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when...\n",
    "...changing the temperature? 0.7 -> 0.5: nothing. 0.7 -> 1.0: nothing\n",
    "...changing max_tokens: Different sentences with the same meaning are generated.\n",
    "...changing top_p? Nothing.\n",
    "...frequency_penalty? Nothing.\n",
    "...presence_penalty? Different sentences with the same meaning are generated.\n",
    "\n",
    "Key Parameters to Explore\n",
    "\n",
    "\t1.\ttemperature:\n",
    "\t•\tDefinition: Controls the randomness or creativity of the model. Lower values make the output more deterministic and repetitive; higher values produce more varied and creative translations.\n",
    "\t•\tImpact: At a lower temperature (e.g., 0.1), the model sticks closer to literal translations and follows strict rules. At higher values (0.7 or more), the model may choose more creative synonyms or expressions that might still capture the intent, but not be as literal.\n",
    "\t2.\tmax_tokens:\n",
    "\t•\tDefinition: Sets the maximum number of tokens (words, punctuation, or subword pieces) that the model will generate.\n",
    "\t•\tImpact: Increasing max_tokens allows for longer translations, which is useful for translating longer texts or languages with lengthier constructions. If set too low, translations might get cut off mid-sentence.\n",
    "\t3.\ttop_p (also known as nucleus sampling):\n",
    "\t•\tDefinition: When set, this parameter controls the diversity of the generated text. Instead of focusing on only the most likely words, it considers a larger pool of candidates based on cumulative probability.\n",
    "\t•\tImpact: Setting top_p = 0.9 (a common value) allows the model to pick among several reasonable translations, improving naturalness and variety. Lower values near 0.1 result in more conservative translations, which might be closer to the literal meaning but less fluent.\n",
    "\t4.\tfrequency_penalty:\n",
    "\t•\tDefinition: Adjusts the penalty for repeating tokens in the output. Higher values reduce the likelihood of repetition.\n",
    "\t•\tImpact: If you’re translating long texts and notice repetitive words, increasing frequency_penalty to something like 0.5 can help the model avoid redundancy. Lower values close to 0 will encourage repetition if that’s required in translations.\n",
    "\t5.\tpresence_penalty:\n",
    "\t•\tDefinition: Similar to the frequency penalty, but it penalizes the model for generating any previously seen token, rather than focusing on frequency.\n",
    "\t•\tImpact: A higher value encourages the model to use new words, which can improve creativity in translations but might lead to unnatural variations if set too high. Ideal for contexts where you want translations to be more engaging or exploratory.\n",
    "\t6.\techo:\n",
    "\t•\tDefinition: If set to true, this parameter instructs the API to return both the input prompt and the generated response.\n",
    "\t•\tImpact: Typically not necessary for translation tasks. If enabled, it can be useful for debugging or understanding what the model is doing, as you’ll see both input and output side-by-side.\n",
    "\t7.\tlogit_bias:\n",
    "\t•\tDefinition: Allows you to bias the output towards (or away from) specific tokens or words by manipulating their logits (probability values).\n",
    "\t•\tImpact: If you want to force the translation to include certain words or avoid using specific words, you can adjust this parameter. For instance, in formal translations, you can penalize informal words or favor technical terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that determines the sentiment of given texts as Positive, Negative, or Neutral.\"},\n",
    "    {\"role\": \"user\", \"content\": \"The service was absolutely fantastic, I loved it!\"}\n",
    "  ],\n",
    "  temperature=0.3,\n",
    "  max_tokens=5,\n",
    "  top_p=0.9,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  n=1,\n",
    "  logprobs=True  # Change from integer to boolean\n",
    ")\n",
    "\n",
    "# Print the output label\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore the mysterious Black Forest that bordered the kingdom. The Black Forest was said to be filled with dark magic and dangerous creatures, but Sir Cedric was undaunted by the tales. Armed with his trusty sword and shield, he ventured deep into the forest, determined to uncover its secrets.\n",
      "\n",
      "As he traveled deeper into the forest, Sir Cedric encountered strange and twisted trees that seemed to whisper to him in an eerie voice. Shadows danced around him, and the air grew thick with a sense\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a storyteller.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Once upon a time in a faraway kingdom, there lived a brave young knight named Sir Cedric. One day, he decided to set off on a journey to...\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=100,\n",
    "  top_p=0.9,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=[\"The End\"],\n",
    "  n=1  # No need to use best_of here in ChatCompletion\n",
    ")\n",
    "\n",
    "# Print the generated text\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_IH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
